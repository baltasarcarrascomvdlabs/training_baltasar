{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is read and a SVD algorithm is applied to the ratings data. Predictions can be obtained using: svd.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fe89a6c91c0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader()\n",
    "ratings = pd.read_csv('~/Downloads/ratings_small.csv')\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "svd = SVD()\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is loaded and NaN values are filled with a blank space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv('~/Downloads/tmdb_5000_movies.csv')\n",
    "movies=movies.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for a simple data cleaning is done. Text based attributes will be converted to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(x):\n",
    "        return str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data cleaning is applied to sokme selected features that will be taken into account in the content based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['id' ,'title','overview']\n",
    "movies_reduced=movies[features]\n",
    "features.remove('id')\n",
    "for feature in features:\n",
    "    movies_reduced[feature] = movies_reduced[feature].apply(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for creating a soup of the features used for the model is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(row):\n",
    "    return row['title']+ ' ' + row['overview']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soup is incorporated as a new column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_reduced['soup'] = movies_reduced.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate distances between text attributes, a Tf/Idf vectorizer is used, discarding stop words of the English language.\n",
    "Then distance is calculated using the cosine ditance between the vectorized attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "count_matrix = tfidf.fit_transform(movies_reduced['soup'])\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "movies_reduced=movies_reduced.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mapping between title and index is defined for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(movies_reduced.index, index=movies_reduced['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for obtaining the top 10 similar movies to a related title is defined. This is obtained by getting the closest movies in terms of cosine distance, using the cosine matrix defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_based_recommendations(title):\n",
    "    title=title.lower()\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    top_10_recommendations =  movies_reduced.iloc[movie_indices]\n",
    "    return top_10_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for incorporating both models is defined, the idea es getting the top 10 similar movies using the content based perspective, and returning the results sorted by the predicted rating obtained with collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_recommendations(title):\n",
    "    top_10_recommendations = get_content_based_recommendations(title, cosine_sim)\n",
    "    top_10_recommendations['Estimated Rating'] = 0\n",
    "    for index, movie in top_10_recommendations.iterrows():\n",
    "        movie['Estimated Rating'] =  svd.predict(1, movie['id'], 3).est\n",
    "        top_10_recommendations.loc[index] = movie\n",
    "    top_10_recommendations = top_10_recommendations.sort_values('Estimated Rating', ascending = False) \n",
    "    return top_10_recommendations\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function you can test recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hybrid_recommendations('john carter')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e1658b66feb60609c1e448f05e4130cca80608a550b5e2251150cb1b045534c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
