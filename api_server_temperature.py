import csv
from datetime import datetime 
import boto3
import json 

'''
Function for getting the path prefix for accesing the mean temperature file in the S3
'''

def get_object_path_prefix():
    today = datetime.now()
    month_day = today.strftime("%m-%d")
    date = str(today.year-2) + "-" + month_day
    path_prefix = 'mean_temperatures/' + date 
    return path_prefix
    
'''
Function for getting mean temperature file name, which is automatically generated by hadoop in the spark job
'''

def get_object_filename(s3_bucket):
    path_prefix = get_object_path_prefix()
    s3_objects = s3_bucket.objects.all()
    for my_bucket_object in s3_objects:
        if(my_bucket_object.key.startswith(path_prefix) and my_bucket_object.key.endswith("csv")):
            filename = my_bucket_object.key
    return filename

'''
Function for reading a csv file not using its path, but instead the actual file
'''

def read_csv(file):
    data = file['Body'].read().decode('utf-8').splitlines() 
    return csv.reader(data)

'''
Function for returning the mean temperature calculated today. It retrieves the data from the csv generated 
in the spark job and stored in a S3 bucket. The csv file is read and the temperature is obtained.
'''

def lambda_handler(context, event):
    s3_resource = boto3.resource(service_name='s3')
    s3_bucket = s3_resource.Bucket('emr-test-bucket-baltasar')
    filename = get_object_filename(s3_bucket)
    mean_temperature_file = s3_bucket.Object(filename).get()
    mean_temperature_csv = read_csv(mean_temperature_file)
    for value in mean_temperature_csv:
        MaximumLastHourTemperature = value
    response = {"Mean temperature today": MaximumLastHourTemperature}
    return response



